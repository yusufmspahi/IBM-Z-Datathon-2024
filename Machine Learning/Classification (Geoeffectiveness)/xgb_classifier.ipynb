{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv('/Users/olliehockey/Library/CloudStorage/OneDrive-ImperialCollegeLondon/Documents/Year 2/Datathon/Imputed_DataFrame.csv')\n",
    "#Data['Accel'] = pd.to_numeric(Data['Accel'].str.replace('*', '', regex=False), errors='coerce')\n",
    "#Data['CentralPA'] = pd.to_numeric(Data['CentralPA'].str.replace('halo', '360', regex=False), errors='coerce')\n",
    "\n",
    "\n",
    "# Features (X) - All columns except the target 'arrival_time'\n",
    "X = data.drop(columns=['Datetime','TransitTime', 'Geoeffective'])\n",
    "\n",
    "y = data['Geoeffective']\n",
    "#80%-20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "param_distributions = {\n",
    "    'n_estimators': [50, 100, 200, 300],       # Number of boosting rounds\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 9],              # Maximum depth of trees\n",
    "    'learning_rate': [0.01, 0.05, 0.1],        # Learning rate\n",
    "    'subsample': [0.6, 0.8, 1.0],              # Subsample ratio for instances\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],       # Subsample ratio for features\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],               # Minimum loss reduction for split\n",
    "    'reg_alpha': [0, 0.01, 0.1],               # L1 regularization term\n",
    "    'reg_lambda': [1, 1.5, 2],                 # L2 regularization term\n",
    "}\n",
    "#setup of model\n",
    "xgboost_model = xgb.XGBClassifier(scale_pos_weight=7.95,use_label_encoder=False, eval_metric='logloss')  # logloss is typical for binary classification\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scores = cross_val_score(xgboost_model, X, y, cv=skf, scoring='roc_auc')\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgboost_model,                # The model to train\n",
    "    param_distributions=param_distributions, # The hyperparameter space\n",
    "    n_iter=50,                              # Number of random combinations to try\n",
    "    scoring='accuracy',        # Scoring metric (MSE for regression)\n",
    "    cv=3,                                   # 3-fold cross-validation\n",
    "    verbose=2,                              # Show output during the process\n",
    "    random_state=42,                        # Reproducibility\n",
    "    n_jobs=-1                               # Use all available cores\n",
    ")\n",
    "#     n_estimators=100,    # Number of boosting rounds (trees)\n",
    "#     max_depth=6,         # Maximum depth of each tree\n",
    "#     learning_rate=0.1,   # Learning rate (controls the contribution of each tree)\n",
    "#     subsample=0.8,       # Subsampling ratio of the training Data\n",
    "#     colsample_bytree=0.8 # Subsampling ratio of the features (columns)\n",
    "# )\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "class_distribution = data['Geoeffective'].value_counts()\n",
    "print(\"this is\", class_distribution)\n",
    "# Train the XGBoost model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best hyperparameters: {random_search.best_params_}\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = random_search.best_estimator_.predict(X_test)\n",
    "y_pred_proba = random_search.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "#smote = SMOTE(random_state=42)\n",
    "#X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "#xgboost_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Evaluate performance using accuracy, classification report, and confusion matrix\n",
    "\n",
    "# Detailed classification metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "threshold = 0.3\n",
    "y_pred_threshold = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "# Confusion matrix with new threshold\n",
    "print(confusion_matrix(y_test, y_pred_threshold))\n",
    "\n",
    "# Calculate ROC AUC\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"ROC AUC: {auc}\")\n",
    "# Plot confusion matrix\n",
    "plt.matshow(confusion_matrix(y_test, y_pred), cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.plot(fpr, tpr, color='blue', lw=2)\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')  # 45-degree line (random guess)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
